import numpy as np

from .base import (
    Task,
    Global,
    SPACE_SIZE,
    cardinal_positions,
    get_spawn_location,
    manhattan_distance,
)
from .space import Node
from .path import (
    path_to_actions,
    estimate_energy_cost,
    find_path_in_dynamic_environment,
)


class VoidSinger(Task):

    def __init__(self, target: Node, protection: float):
        super().__init__(target)
        self.protection = protection

    def __repr__(self):
        return f"{self.__class__.__name__}{self.target.coordinates}"

    def completed(self, state, ship):
        if not ship.can_move() and ship.node != self.target:
            return True
        return False

    @classmethod
    def generate_tasks(cls, state):
        protection_array = estimate_protection(state)
        reward_nodes = set(state.space.reward_nodes)

        for ship in state.fleet:
            if isinstance(ship.task, VoidSinger):
                target = ship.task.target
                if target in reward_nodes:
                    reward_nodes.remove(target)

        tasks = []
        for reward_node in reward_nodes:
            protection = float(protection_array[reward_node.coordinates])
            tasks.append(cls(reward_node, protection))
        return tasks

    def evaluate(self, state, ship):
        if not ship.can_move():
            if ship.node == self.target:
                return 1000
            else:
                return 0

        if ship.energy < self.protection:
            return 0

        rs = state.grid.resumable_search(ship.unit_id)
        path = rs.find_path(self.target.coordinates)
        if not path:
            return 0
        if len(path) > state.steps_left_in_match():
            return 0

        energy_needed = estimate_energy_cost(state.space, path)

        spawn_point = get_spawn_location(state.team_id)
        spawn_distance = manhattan_distance(self.target.coordinates, spawn_point)
        middle_lane_distance = max(spawn_distance - SPACE_SIZE, 0)

        p = Global.Params
        score = (
            p.VOID_SINGER_INIT_SCORE
            + p.VOID_SINGER_PATH_LENGTH_MULTIPLIER * len(path)
            + p.VOID_SINGER_ENERGY_COST_MULTIPLIER * energy_needed
            + p.VOID_SINGER_NODE_ENERGY_MULTIPLIER * self.target.energy_gain
            + p.VOID_SINGER_MIDDLE_LANE_DISTANCE_MULTIPLIER * middle_lane_distance
        )

        return score

    def apply(self, state, ship):
        path = find_path_in_dynamic_environment(
            state,
            start=ship.coordinates,
            goal=self.target.coordinates,
            ship_energy=ship.energy,
        )
        if not path:
            return False

        energy_needed = estimate_energy_cost(state.space, path)
        if energy_needed > ship.energy:
            path = find_path_in_dynamic_environment(
                state,
                start=ship.coordinates,
                goal=self.target.coordinates,
                ship_energy=ship.energy,
                grid=state.grid.energy_with_low_ground,
            )

        ship.action_queue = path_to_actions(path)
        return True


def estimate_protection(state):
    protection = np.zeros((SPACE_SIZE, SPACE_SIZE), dtype=np.int16)
    for opp_ship in state.opp_fleet.ships:
        if opp_ship.node is None or opp_ship.energy <= 0:
            continue

        x, y = opp_ship.coordinates
        protection[x, y] += opp_ship.energy
        for x_, y_ in cardinal_positions(x, y):
            protection[x_, y_] += opp_ship.energy

    return protection
